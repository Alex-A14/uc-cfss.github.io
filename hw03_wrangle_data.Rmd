---
title: "Homework 03: Exploring and wrangling data"
output: html_document
---

# Overview

Due before class Wednesday January 25th.

The goal of this assignment is to practice wrangling and exploring data in a research context.

# Fork the `hw03` repository

Go [here](https://github.com/uc-cfss/hw03) to fork the repo for homework 03.

# Part 1: Tidying messy data

In the `rcfss` package, there is a data frame called `dadmom`.

```{r, echo = FALSE, message = FALSE}
library(tidyverse)
library(rcfss)

data("dadmom")
dadmom
```

Tidy this data frame so that it adheres to the tidy data principles:

1. Each variable must have its own column.
1. Each observation must have its own row.
1. Each value must have its own cell.

# Part 2: Wrangling and exploring messy(ish) data

The [Supreme Court Database](http://scdb.wustl.edu/) contains detailed information of decisions of the U.S. Supreme Court. It is perhaps the most utilized database in the study of judicial politics. Until recently, the database only contained records on cases from the "modern" era (1946-present). Recently the database was extended backwards to include all decisions since the formation of the Court in 1791. While still in beta form, this extension opens the doors to new studies of the Court's pre-modern era decisions.

In the `hw02` repository, you will find two data files: `SCDB_Legacy_03_justiceCentered_Citation.csv` and `SCDB_2016_01_justiceCentered_Citation.csv`. These are the exact same files you would obtain if you downloaded them from the original website; I have included them in the repository merely for your convenience. Documentation for the datasets can be found [here](http://scdb.wustl.edu/documentation.php). The data is structured in a tidy fashion. That is, every row is a vote by one justice on one case for every case decided from the 1791-2015 terms.^[Terms run from October through June, so the 2015 term contains cases decided from October 2015 - June 2016] There are several ID variables which are useful for other types of research: for our purposes, the only ID variable you need to concern yourself with is `caseIssuesId`. Variables you will want to familiarize yourself with include: `term`, `justice`, `justiceName`, `decisionDirection`, `majVotes`, `minVotes`, `majority`, and `chief`. Pay careful attention in the documentation to how these variables are coded.

In order to analyze the Supreme Court data, you will need to import these two files and combine them together (see `bind_rows()` from the `dplyr` package).^[Friendly warning: you will initially encounter an error attempting to join the `tibbles`. Use your powers of deduction (and Google/Stack Overflow/classmates/me and the TA) to figure out how to fix this error.]

Once joined, use your data wrangling and exploratory data analysis skills to answer the following questions:

1. What percentage of cases in each term are decided by a one-vote margin (i.e. 5-4, 4-3, etc.)
1. In each term he served on the Court, in what percentage of cases was Justice Antonin Scalia in the majority?
    * Advanced challenge: Create a graph similar to above that compares the percentage for all cases versus non-unanimous cases (i.e. there was at least one dissenting vote)
1. In each term, what percentage of cases were decided in the conservative direction?
    * Advanced challenge: The Chief Justice is frequently seen as capable of influencing the ideological direction of the Court. Create a graph similar to the one above that also incorporates information on who was the Chief Justice during the term.

# Submit the assignment

Your assignment should be submitted as two RMarkdown documents. Follow instructions on [homework workflow](hw00_homework_guidelines.html#homework_workflow). As part of the pull request, you're encouraged to reflect on what was hard/easy, problems you solved, helpful tutorials you read, etc.

# Rubric

Check minus: Displays minimal effort. Doesn't complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn't use plots appropriate for the variables being analyzed. No record of commits other than the final push to GitHub.

Check: Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output). Nothing spectacular, either bad or good.

Check plus: Finished all components of the assignment correctly and attempted at least one advanced challenge. Code is well-documented (both self-documented and with additional comments as necessary). Graphs and tables are properly labeled. Use multiple commits to back up and show a progression in the work. Analysis is clear and easy to follow, either because graphs are labeled clearly or you've written additional text to describe how you interpret the output.
